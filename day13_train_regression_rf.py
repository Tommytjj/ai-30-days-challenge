# train_regression.py â€”â€” Day 13 å›å½’å®æˆ˜ï¼ˆæ”¯æŒç¦»çº¿ fallbackï¼‰
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.pipeline import Pipeline
import joblib
import numpy as np
from sklearn.ensemble import RandomForestRegressor

# ==============================
# 1. åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®ï¼ˆå¸¦ fallbackï¼‰
# ==============================
print("ğŸ“¥ æ­£åœ¨åŠ è½½åŠ å·æˆ¿ä»·æ•°æ®...")

# å°è¯•åŠ è½½çœŸå®æ•°æ®
try:
    from sklearn.datasets import fetch_california_housing
    housing = fetch_california_housing()
    print("âœ… æˆåŠŸåŠ è½½çœŸå®åŠ å·æˆ¿ä»·æ•°æ®ï¼")
except Exception as e:
    print(f"âš ï¸ æ— æ³•åŠ è½½çœŸå®æ•°æ® ({type(e).__name__}: {e})ï¼Œæ­£åœ¨åˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ•°æ®...")
    
    # --- ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ›¿ä»£ ---
    from sklearn.datasets import make_regression
    
    X_sim, y_sim = make_regression(
        n_samples=20640,
        n_features=8,
        n_informative=6,
        noise=100,
        random_state=42
    )
    
    # ç¼©æ”¾ç›®æ ‡å€¼åˆ°åˆç†æˆ¿ä»·èŒƒå›´ [0.15k, 5.0k]
    y_sim = (y_sim - y_sim.min()) / (y_sim.max() - y_sim.min())
    y_sim = y_sim * (5.0 - 0.15) + 0.15
    
    # æ„é€ å…¼å®¹å¯¹è±¡
    class MockHousing:
        def __init__(self):
            self.data = X_sim
            self.target = y_sim
            self.feature_names = [
                'MedInc', 'HouseAge', 'AveRooms', 'AveBedrms',
                'Population', 'AveOccup', 'Latitude', 'Longitude'
            ]
            self.DESCR = "Simulated California Housing Dataset (offline fallback)"
    
    housing = MockHousing()
    print("âœ… å·²åˆ‡æ¢åˆ°æ¨¡æ‹ŸåŠ å·æˆ¿ä»·æ•°æ®ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")

# æå–ç‰¹å¾å’Œç›®æ ‡
X, y = housing.data, housing.target

print(f"ğŸ“Š æ•°æ®è§„æ¨¡: {X.shape[0]} æ¡æ ·æœ¬, {X.shape[1]} ä¸ªç‰¹å¾")
print(f"ğŸ·ï¸  ç‰¹å¾å: {housing.feature_names}")
print(f"ğŸ’° ç›®æ ‡ï¼ˆæˆ¿ä»·ä¸­ä½æ•°ï¼‰èŒƒå›´: ${y.min():.1f}k - ${y.max():.1f}k")

# ==============================
# 2~7. åŸæœ‰è®­ç»ƒæµç¨‹ï¼ˆå®Œå…¨ä¸å˜ï¼‰
# ==============================

# 2. åˆ’åˆ†è®­ç»ƒé›†/æµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. æ„å»ºå›å½’ Pipeline
pipeline = Pipeline([
    ('scaler', StandardScaler()),
     ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))
])

# 4. è®­ç»ƒ
pipeline.fit(X_train, y_train)

# 5. é¢„æµ‹
y_pred = pipeline.predict(X_test)

# 6. è¯„ä¼°ï¼ˆå›å½’ä¸‰å¤§æŒ‡æ ‡ï¼‰
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("\nâœ… å›å½’æ¨¡å‹è¯„ä¼°ç»“æœ:")
print(f"  MAE (å¹³å‡ç»å¯¹è¯¯å·®): ${mae:.2f}k")
print(f"  RMSE (å‡æ–¹æ ¹è¯¯å·®): ${rmse:.2f}k")
print(f"  RÂ² (å†³å®šç³»æ•°): {r2:.4f} (è¶Šæ¥è¿‘1è¶Šå¥½)")

# 7. ä¿å­˜æ¨¡å‹
joblib.dump(pipeline, 'california_housing_pipeline_v1_rf.joblib')
print("\nğŸ’¾ å›å½’ Pipeline å·²ä¿å­˜ä¸º california_housing_pipeline_v1_rf.joblib")